########################################################################################################

# The R code begins on line 106, and is suggested to be run in RStudio. The workflow is described immediately, below.

# If the working directory (line 106) is set to a folder containing the files described immediately below, this entire R file may be highlighted, and run with a single control + return click.
# This workflow is based on a BOLD data file, and will generate the below analyses, tables and figures based on the contents of subsequently updated (by BOLD users) data files.
# This workflow is adaptable to an ordinal-level dataset for any taxon.

# This workflow requires the following files be in the working directory:

# R_code_suporting_file_r_made_divergence_april_30.csv
# R_code_suporting_file_RodgPrimers_Apr17.csv
# R_code_suporting_file_primer_code.csv
# R_code_suporting_file_concordance_status.csv
# R_code_suporting_file_Main_data_plus_tentative_new_species.csv
# R_code_suporting_file_other_exclusions.csv
# R_code_suporting_file_permissions_mar_17.csv
# R_code_suporting_file_species_checklist.csv

# Subsequently, running the full code produces the following files:

# Main_Data_source_after_pre.filtering.csv
# BINs_without_names_from_main_data_source.csv
# COL_Tentative_new_species_records_for_Canada.csv
# COL_Species_whose_COL_synonyms_are_accepted_names_that_match_the_checklist_update_these_on_BOLD.csv
# COL_Status_of_Checklist_Names_on_COL.csv
# USE_this_file_for_a_Distance_Summary_***these_are_ProcessIDs_of_species_in_Concordant_BINs.csv
# USE_this_file_for_a_Discordance_report_***these_are_ProcessIDs_of_IDd_specimens_with_>500bp.csv
# FIGURE_sequence_sources.pdf
# FIGURE_Primer_plot.pdf
# FIGURE_histogram_of_seq_length_by_year.pdf
# TABLE_Checklist_based_Species_Table_w_species.level_summaries.csv
# TABLE_Summary_of_Library_and_Main_dataset_contents.csv
# Library_species_with_>_2_Pcent_mean_divergence.csv
# IDENTIFIERS_of_IDd_specimens_with_>500bp.csv

# This workflow has three main parts, Data Reading, Data Cleaning, and Data Manipulation & Analyses, which are described below.

#  DATA READING
# The data is read in with a header row, whitespaces are removed, and all missing values are replaced with "NA". These data are generated by the BOLD team, through a search querying "Hemiptera", from Canada, the U.S. and Mexico.
# This data file is called: R_code_suporting_file_data_mar_31.csv
# Next, several additional files are read in. These are:
# R_code_suporting_file_species_checklist.csv = This a csv version of the Maw et al. 2000 checklist
# R_code_suporting_file_permissions_mar_17.csv = A list of project codes for which we have permission to release data.
# R_code_suporting_file_other_exclusions.csv = other projects that should not be released
# R_code_suporting_file_concordance_status.csv = This file only becomes available once a concordance analysis is done on BOLD, and then it NEEDS TO BE MADE, BY HAND, from the concordance report. Once this is done, this file should be re-read in, and all lines re-run until that point.

# DATA CLEANING (the below is the stepwise flow of data cleaning).
# duplicates, if any are removed via the Process.ID
# Flagged records, based on the flagged records column are removed
# a "Suborder" column is added, with suborder assigned to each specimen based on a family level match with the Maw et al. checklist. If BOLD has not provided a family ID, the NA values of the suborder column are labeled "Not.assigned".
# The dataset is filtered (using the projects in the permissions list) to only contain release-able records.
# Ibid for other_exclusions.
# The dataset is filtered for only records identified to order == "Hemiptera".
# The dataset is filtered to remove records from GenBank.
# Species names are cleaned by copying the "Species" column, renaming it cleanspecies, and replacing entries that are not clearly in "Genus species" format with "NA". This removes subspecific epithets from trinomials, entries of "Genus sp.", and other non "Genus species" entries.

# DATA MANIPULATION & ANALYSIS 

# The workflow produces several tables, and figures: 

# The data is subset by matches to the Maw et al. 2000 checklist, including all non-matching specimens with Canadian localities.
# Specimens from Canada, with names not matching the checklist, represent potential new records and these names are automatically queried for validity against the Catalogue of life (COL).
# Specimens with Non-matching names whose synonyms, from the COL results, match the Checklist are written to a file, so their names can be updated on bold.
# (This is the file named: COL_Species_whose_COL_synonyms_are_accepted_names_that_match_the_checklist_update_these_on_BOLD_*current date*.csv)
# The remaining non-matching records are removed from the dataset, and written to the file: COL_Tentative_new_species_records_for_Canada_*current date*.csv
# Lastly the checklist is queried against COL, and the results are written to the file: COL_Status_of_Checklist_Names_on_COL_*current date*.csv 
# The main data file (called "main" in the code) from the above processes contains all releasable records that either match the checklist, or are from Canada. This dataset is written to the file: Main_Data_source_after_pre.filtering_*current date*.csv
# The main data file will be given a DOI.

# BINs in the "main" dataset, that do not contain any specimens named to species, are identified and written to the file: BINs_without_names_from_main_dataframe_*current date*.csv

# Vector Categories are created for the different kinds of data sources, identification sources, sequence length, and year that will be used for the figures, and could be used for further analyses.

# THE DNA BARCODE REFERENCE LIBRARY - The data is subset to only specimens identified to species, that have >= 500bp of sequence data - this dataset becomes the "DNA Barcode Library" and will be given a DOI
# Process IDs from the library are written to the file: USE_for_a_Discordance_report_***these_are_ProcessIDs_of_IDd_specimens_with_>500bp_*current date*.csv
# The above process IDs are used to run a discordance report on BOLD. The results must be formatted BY HAND into the input file (above): R_code_suporting_file_concordance_status.csv
# Once the file R_code_suporting_file_concordance_status.csv (or one like it) is generated, the code should be re-run up until that point. This will create a vector of concordance status on BOLD, for every specimen.

# The data are subset by specimens that are only 'concordant' on BOLD (this information comes from the concordance report, as above), and are written to the file: USE_for_a_Distance_Summary_***these_are_ProcessIDs_of_species_in_Concordant_BINs_*current date*.csv
# BOLD distance summaries are returned as excel spreadsheets. Queries with many (hundreds) of specimens per species may exceed the computational ability of BOLD, and queries with large intraspecific sampling may need to be done in batches where each batch contains ALL the members of a given species (so intraspecific distances can be accurately calculated).
# The distance summary spreadsheets from BOLD can be quite large, and when recombining them into one file may exceed the row storage limit of excel. Therefore, I recommend converting each batch-as-spreadsheet into a CSV file, and combined them in R, to produce a file formatted as the input file: r_made_divergence_april_30.csv
# Summary statistics, per Library species, are calculated from the distance summary and written to the species level table (described below). 
# All Library specimens whose species show > 2% mean divergence are written to the file: Library_species_with_>_2_Pcent_mean_divergence_*current date*.csv

# The data are subset by specimens identified by only well recognized taxonomists (chosen by R. Gwiazdowski), and a within-code 'BIN discordance report' is generated from these data.
# A 3D discordance-space figure is generated based on the local 'BIN discordance report', and coloured based on the BIN discordance reported from BOLD.
# The taxonomists used in the data set for this figure, along with the number of specimens identified by each, is written to the file: IDENTIFIERS_of_IDd_specimens_with_>500bp_*current date*.csv 

# TABLES
# A species level table of summary information for the abundance, diversity, divergence, and concordance status for each species is written onto the Maw et al. 2000 checklist, and is the file: TABLE_Checklist_based_Species_Table_w_species.level_summaries_*current date*.csv
# An ordinal level table of main and Library summary information for the abundance, diversity, divergence, and concordance status for each suborder is written as the file: TABLE_Summary_of_Library_and_Main_dataset_contents_*current date*.csv

# FIGURES
# Note: when produced in R Studio, the viewing window size governs the saved figure size. A small viewing window will produce collapsed, or difficult to view PDFs.
# Based on the data-source vector categorization, a proportional histogram of datasources, filled with sequence length is written to the file: FIGURE_histogram_of_seq_length_by_year.pdf
# The Process IDs from the 'main' dataset are used by the BOLD team to produce the two files: R_code_suporting_file_RodgPrimers_Apr17.csv, and R_code_suporting_file_primer_code.csv 
# These two files are used to produce a heat-index bubble diagram of primer usage and proportion of amplification by family, and is written to the file: FIGURE_Primer_plot.pdf
# Based on the data-source vector categorization, a proportional histogram of sequence length by specimen-collection year is written to the file: FIGURE_sequence_sources.pdf

# End of workflow.
########################################################################################################
# The code begins immediately, below.

###### READ IN THE DATA, CHECKLIST, AND LIST OF PERMISSIONS (To filter for usable data)
setwd("/Users/Rodger/Desktop/run_R_from_here")
first <- read.csv("R_code_suporting_file_Main_data_plus_tentative_new_species.csv", header =T, strip.white=TRUE, na.strings=c("")) # for other characters na.strings=c("",".","NA")#Works
checklist <- read.csv("R_code_suporting_file_species_checklist.csv", header=T) # This is a CSV version of the Maw et al. 2000 checklist. colname with species is: checklist_species
permissions <- read.csv("R_code_suporting_file_permissions_mar_17.csv", header=T) # This is a list of projects for which we can freely release data. colname with permissions is: perms
concordance <- read.csv("R_code_suporting_file_concordance_status.csv", header =T, strip.white=TRUE, na.strings=c("")) # This file is made by hand, and will become available once a concordance analysis is done on BOLD (details below)
other_exclusions <- read.csv("R_code_suporting_file_other_exclusions.csv", header=T) # colname with exclusions is: exclude
first[first == "NA"] <- NA # NAs from a previously read in csv seem to be read as "NA" rather than NA, use this to change them back.
first$concordance.status <- concordance$Rank.of.Conflict[match(first$BIN, concordance$BIN)] # This establishes a vector/column of concordance levels, and only works once a file like the above R_code_suporting_file_concordance_status.csv has been produced (from a discordance report, and read in by hand)
#remove_dups <- which(duplicated(first$Process.ID)) # for reasons I can't entirely work out, I found a few duplicates in the main data file...
#first <- first[-remove_dups,] # ibid The above two lines are not necessary for reproducing the analyses from the supplementary data files
first <- droplevels(subset(first, is.na(first$Flagged.Record))) # this removes everything with an entry in the flagged record column.
first$Suborder <- checklist$suborder[match(first$Family, checklist$family)] # adds a Suborder column
first$Suborder <- as.character(first$Suborder)
first$Suborder[is.na(first$Suborder)] <- "Not.assigned"
second <- droplevels (subset(first, (first$Project.Code %in% permissions$perms ))) # This subsets for just release-able records (as of April 2014)
third <- droplevels (subset(second, !(second$Project.Code %in% other_exclusions$exclude ))) # This subsets for other exclusions
fourth <- droplevels(subset(third, third$Order == "Hemiptera")) #This excludes everything not ID'd to Order
fifth <- droplevels(subset(fourth, complete.cases(fourth$Institution))) # This removes all records without "Instution
data <- droplevels (subset(fifth, fifth$Institution!="Mined from GenBank, NCBI")) # This excludes everything from GenBank

###### CLEAN SPECIES NAMES (This creates a NEW column of species names (cleanspecies), and cleans it, returning just binomials)
data$cleanspecies <- data$Species
data$cleanspecies <- gsub("[^.]*[[:punct:]][^.]*|sp$|[^.]*\\d[^.]*", "NA", data$cleanspecies, perl = TRUE) # Removes entire string if it contains: any punctuation, any numbers, and and all instances of "sp" (i.e. all "genus sp.", "sp.", "sp", "species 5", or "MS-DAA")
data$cleanspecies <- gsub("([A-z]+\\s[A-z]+) .*", "\\1", data$cleanspecies) # This removes the second space, and everything after (removes trinomials)
data$cleanspecies <- gsub("^[^\\s]*$", "NA", data$cleanspecies, perl = TRUE) #Removes single entries (i.e. Genus only). Match to beginning and end every string that does not include a space; Removes everything in a string without a space in between it (usually Genus-only entries). 
data$cleanspecies <- as.factor(data$cleanspecies) # Somehow, the above deletions transform the vector from factors, to characters. This turns them back
data$cleanspecies[data$cleanspecies == "NA"] <- NA # Somehow, creating the new column makes the NA's a character ("NA"), not NA. This turns "NA" into NA.
exclude <- read.csv("species_to_exclude.csv", header =T, strip.white=TRUE, na.strings=c("")) # for other characters na.strings=c("",".","NA")#Works
data <- droplevels (subset(data, !(data$cleanspecies %in% exclude$Species ))) # This is a last-minute addition, to remove a short list of 8 Cicadellid species of very questionable validity.

###### SUBSET THE DATA BY MATCHES TO THE MAW ET AL. 2000 CHECKLIST(regardless of collection locality), AND ALL SPECIMENS FROM CANADA
matches <- droplevels  (subset (data, data$cleanspecies %in%  checklist$checklist_species))#This is a subset of all rows whose species match the checklist
# The code below includes canadian specimens not included in the above list.
nonprocessid <- droplevels (subset(data, !(data$Process.ID %in% matches$Process.ID )))# This is a subset of the original dataset, minus the entries from matches (above), so that when we subset by location, below, we don't count 'matches' twice.
justcanada <- droplevels  (subset (nonprocessid, nonprocessid$Country.Ocean=="Canada"))# These are all specimens from Canada that do not have matching species names to the checklist (will contain NA's, and 'new' species occurances)
###### The code below finds 'new' canadian records, by filtering all records by the checklist.
NewCanadasp_species <- subset(justcanada, !is.na(justcanada$cleanspecies)) # This is just specimens from Canada - with species names - that do not match the checklist
write.csv(NewCanadasp_species, file=paste("LIST_of_specimens_records_that_are_tentative_new_species_to_Canada", as.Date(Sys.time()), ".csv", sep = ""), row.names = FALSE)
# Canada, below, contains only species consistent with the checklist, or specimens from Canada without species IDs
Canada <- droplevels (subset(justcanada, !(justcanada$cleanspecies %in% NewCanadasp_species$cleanspecies ))) # This removes all specimens with species names that are not from the checklist (it preserves NAs)
main <- rbind(matches, Canada) #this brings together checklist matches, and all unnamed Canadian specimens
write.csv(main, file = paste("Main_Data_source_after_pre.filtering_", as.Date(Sys.time()), ".csv", sep = ""), row.names = FALSE) 
###### Hereafter, this source dataset for subsequent use is called "main" ######

###### FIND BINS FROM MAIN DATASET NOT MATCHING ANY SPECIES
df.of.just.species.names <- droplevels (subset(main,complete.cases(main$cleanspecies))) # These are all specimens that have species names
list.of.bins.with.species <- unique(df.of.just.species.names$BIN) # This is a unique list of BINs associated with species names
unnamed.bins <- droplevels (subset(main, !(main$BIN %in% list.of.bins.with.species))) # These are all specimens (from the original dataset) whose BINs do not match BINs affiliated with species names
write.csv(unnamed.bins, file = paste("BINs_without_names_from_main_data_source_", as.Date(Sys.time()), ".csv", sep = ""), row.names = FALSE) 
length(unique(unnamed.bins$BIN))

###### QUERY THE TENTATIVE 'NEW' CANADIAN SPECIES' NAMES AGAINST THE CATALOGUE OF LIFE (COL) ##########
#This will require the following packages:
install.packages("taxize")
install.packages("plyr")
require(taxize) # This package contains functions to search COL, ITIS, et al.
require(plyr)
###### Hat-tip to Mike Rosario (Duke Univ.) for personal help with the function, below.  
###### The COL query drops species that do not match its database, this function replaces those queries in the output file.
listToDataframe <- function(myList, myNames){
  ldply(myList) -> output
  
  #find which names have no entries
  setdiff(myNames, output[,1]) -> naRows
  
  if(length(naRows)!=0){ #only executes if rows of NAs need to be added
    for(i in naRows){
      #create a vector with the names, and the rest NAs
      c(i, rep(NA, ncol(output)-1)) -> toAdd
      
      #append the vector to the end of the output
      output <- rbind(output, toAdd)
    }
  }
  return(output)
}
# This is the end of the function: listToDataframe.
newsp <- unique(NewCanadasp_species$cleanspecies) # This is a unique list of all the species names, from Canada, that do not match the checklist.
write.csv(newsp, file = paste("newsp_that_go_into_COL_search_", as.Date(Sys.time()), ".csv", sep = ""), row.names = FALSE)
COL <- col_search(name=newsp) # This is the taxize package query for COL
COL_results <- listToDataframe(myList=COL, myNames=NewCanadasp_species$cleanspecies) # This combines the COL results, and the species initially queried, but dropped in its search.
#not_in_COL <- droplevels(subset(COL_results, is.na(COL_results$status)))
syn_on_checklist <- droplevels  (subset (COL_results, COL_results$acc_name %in%  checklist$checklist_species))
write.csv(syn_on_checklist, file = paste("COL_Species_whose_COL_synonyms_are_accepted_names_that_match_the_checklist_update_these_on_BOLD_", as.Date(Sys.time()), ".csv", sep = ""), row.names = FALSE) # These are specimens whose COL accepted name is a synonym matching a species on the checklist.
tentative_new_species <- droplevels  (subset (COL_results, !(COL_results$acc_name %in%  checklist$checklist_species)))
write.csv(tentative_new_species, file = paste("COL_Tentative_new_species_records_for_Canada_", as.Date(Sys.time()), ".csv", sep = ""), row.names = FALSE)
str(tentative_new_species)
length(unique(tentative_new_species$cleanspecies))

###### QUERY THE CHECKLIST AGAINST THE CATALOGUE OF LIFE ######
# This query searches almost 4K records, and the search time can take 10 minutes, or more.
checklist.spp <- unique(checklist$checklist_species) # It appears the search prefers a list/table rather than a vector (though I'm not certain about this).
checklist_on_COL <- col_search(name=checklist.spp)
check <- listToDataframe(myList=checklist_on_COL, myNames=checklist$checklist_species)
check.on.col <- data.frame(check)
write.csv(check.on.col, file = paste("COL_Status_of_Checklist_Names_on_COL_", as.Date(Sys.time()), ".csv", sep = ""), row.names = FALSE)

###### THE BELOW CREATES SEVERAL CATEGORIES OF DATASOURCES, SEQUENCE LENGTH, AND YEAR - THAT WILL BE USED FOR FIGURE, AND COULD BE USED FOR OTHER ANALYSES

# THIS CREATES A VECTOR OF DATA SOURCES BY USING THE PROJECT CODE. These data sources for these codes can be had from the BOLD projects page, or the BOLD team.
biobus <- c("BBHEM", "BBHMA", "USHEM", "BBHCN", "BBPEC", "BBGAL")
malaise <- c("CNBAA", "CNBAB", "CNBAC", "CNBAD", "CNBAE", "CNBAF", "CNBAG", "CNBAH", "CNBAI", "CNBAK", "CNBAM", "CNBPA", "CNBPB", "CNBPC", "CNBPD", "CNBPE", "CNBPF", "CNBPG", "CNBPH", "CNBPI", "CNBPJ", "CNBPK", "CNBPL", "CNBPM", "CNBPN", "CNBPO", "CNBPP", "CNBPQ", "CNBPR", "CNBPT", "CNEIA", "CNEIB", "CNEIC", "CNEID", "CNEIE", "CNEIF", "CNEIG", "CNEIH", "CNEII", "CNEIJ", "CNGIA", "CNGIB", "CNGIC", "CNGID", "CNGIE", "CNGIF", "CNGIG", "CNGIH", "CNGIK", "CNGIL", "CNGIN", "CNGLA", "CNGLB", "CNGLC", "CNGLD", "CNGLE", "CNGLF", "CNGRB", "CNGRC", "CNGRD", "CNGRE", "CNGRF", "CNGRG", "CNGRH", "CNGRI", "CNGRJ", "CNGRK", "CNGRL", "CNGRM", "CNGRN", "CNJAA", "CNJAB", "CNJAC", "CNJAD", "CNJAE", "CNJAF", "CNJAG", "CNJAH", "CNJAI", "CNJAJ", "CNPAA", "CNPAB", "CNPAC", "CNPAD", "CNPAE", "CNPAF", "CNPAG", "CNPAH", "CNPAI", "CNPAJ", "CNPAK", "CNPAL", "CNPAM", "CNPAN", "CNPAO", "CNPAP", "CNPAQ", "CNPAR", "CNPCD", "CNPCE", "CNPCG", "CNPCN", "CNPCP", "CNPCQ", "CNPCR", "CNPCS", "CNPPA", "CNPPB", "CNPPC", "CNPPD", "CNPPE", "CNPPF", "CNPPG", "CNPPH", "CNPPI", "CNPPJ", "CNRMA", "CNRMB", "CNRMC", "CNRMD", "CNRME", "CNRMF", "CNRMG", "CNRMH", "CNSLA", "CNSLB", "CNSLC", "CNSLD", "CNSLE", "CNSLF", "CNSLG", "CNSLH", "CNSLI", "CNSLJ", "CNSLK", "CNSLL", "CNSLM", "CNSLN", "CNSLO", "CNSLP", "CNSLQ", "CNSLR", "CNSLS", "CNSLT", "CNSLU", "CNWBA", "CNWBB", "CNWBC", "CNWBD", "CNWBE", "CNWBF", "CNWBG", "CNWBH", "CNWLA", "CNWLB", "CNWLC", "CNWLD", "CNWLE", "CNWLF", "CNWLG", "CNWLH", "CNWLI", "CNWLJ", "CNWLK", "CNWLL", "CNWLM", "CNWLN", "CNWLO", "CNWLP", "CNWLQ", "CNGII", "CNGIJ", "CNGIM", "CNPCI", "GMGAA", "GMGBB", "GMGCC", "GMGDD", "GMGEE", "GMGFF", "GMGSA", "GMGSB", "GMGSC", "GMGSD", "GMGSE", "GMGSF", "GMGSG", "GMGSH", "GMGSI", "GMGSJ", "GMGSK", "GMGSL", "GMGSM", "GMGSN", "GMGSO", "GMGSP", "GMGSQ", "GMGSR", "GMGSS", "GMGST", "GMGSU", "GMGSV", "GMGSW", "GMGSX", "GMGSY", "GMGSZ", "GMNCA", "GMNCB", "GMNCC", "GMNCD", "GMNCE", "GMNCF", "GMNCG", "GMNCH", "GMNCJ", "GMNCL", "GMNCM", "GMNCO", "GMNCP", "PAAPR", "PAAUG", "PAJUL", "PAJUN", "PAMAY", "PANOV", "PASEP", "PHAPR", "PHAUG", "PHJUL", "PHJUN", "PHMTV", "PHNOV", "PHOCT", "PHSEP", "SONE", "HEAPR", "HEAUG", "HEJUL", "HEMAY", "HENOV", "HEOCT", "HESEP", "JSHMA", "JSJUL", "JSJUN", "JSMAY", "JSOCT", "JSSEP", "ASHMT")
bio_other <- c("DSCFV", "CICBC", "CAARC", "DSAPH", "ENLCW", "SAPIT", "SICT", "DBSI", "DIMC", "ERPIR", "OAAS", "AEDNA", "ASAHE", "ASGCB", "SSBAA", "SSBAB", "SSBAC", "SSBAD", "SSBAE", "SSBAF", "SSEBB", "SSEIA", "SSEIB", "SSEIC", "SSEID", "SSJAA", "SSJAB", "SSJAC", "SSJAD", "SSJAE", "SSJAF", "SSJEE", "SSPAA", "SSPAB", "SSPAC", "SSPAE", "SSPAG", "SSPCC", "SSWEE", "SSWLA", "SSWLB", "SSWLC", "SSWLD", "SSWLE", "SSWLF", "DSPKJ", "PHFLO", "NCCD", "PHGGC", "TTBHT", "TTHFW", "CHIP", "CNPPX")
museum <- c("SIHET", "UDCC", "LHASA", "HCNC", "HCNCS", "PFC", "CNCHA", "CNCHB", "CNCHC", "CNCHF", "CNCHG", "RDBA", "RDBAB", "RFAAP", "RFADL", "RFAPS", "RFBAC", "RFBAD", "RFBAE", "RFBAF", "RFBAG", "RFBAX", "RFCHP", "RFGM", "RFKPE", "RFKSQ", "RFLA", "RFMEL", "RFMI", "RFMIS", "RFPB", "RFPBB", "RFPHX", "RFPSY", "RFQC", "RFVAC", "AHCNC", "RFBGA", "RFKSM", "RFKSP", "DSHEM", "HCNCA", "HCNCX", "POCV", "HMAZ")
main$source.group <- main$Project.Code
main$source.group <- gsub(paste(biobus, collapse = "|"), "BioBus", main$source.group)
main$source.group <- gsub(paste(malaise, collapse = "|"), "Malaise", main$source.group)
main$source.group <- gsub(paste(bio_other, collapse = "|"), "BIO related", main$source.group)
main$source.group <- gsub(paste(museum, collapse = "|"), "Museum", main$source.group)
unique(main$source.group) # Check to be sure all groups are covered

# THIS CREATES A VECTOR OF SEQUENCE LENGTH AS JUST NUMBERS - removing "bp" (By copying the seq length column, and cleaning that)
main$seq.length <- as.integer(gsub("\\[.*\\]", "", main$COI.5P.Seq..Length))

# THIS FUNCTION FINDS, AND REMOVES ROWS BASED ON SEQUENCE LENGTH FOR THOSE > 700bp
longseqs <- length(which(main$seq.length >700))
if(longseqs > 0) {remove <- which(main$seq.length >700) 
                  main <- main[-c(remove), ] 
}
longseqs

#main$seq.length <- as.integer(main$seq.length)

# THIS CREATES A VECTOR OF CATEGORIES, BASED ON SEQUENCE LENGTH
main$seq.cat[main$seq.length > 600] <- "over 600"#works, although note that a vector cannot be factor, and this was changed above
main$seq.cat[main$seq.length > 500 & main$seq.length <= 658] <- "500-658"#works
main$seq.cat[main$seq.length > 300 & main$seq.length <= 500] <- "300-500"#works
main$seq.cat[main$seq.length > 100 & main$seq.length <= 300] <- "100-300"#works
main$seq.cat[main$seq.length > 0 & main$seq.length <= 100] <- "0-100"#works
main$seq.cat[main$seq.length ==0] <- "Zero"#works

# THIS CREATES an alternate VECTOR OF CATEGORIES, BASED ON SEQUENCE LENGTH
main$seq.cat.2[main$seq.length > 600] <- "over 600"#works, although note that a vector cannot be factor, and this was changed above
main$seq.cat.2[main$seq.length > 500 & main$seq.length <= 658] <- "500-658"#works
main$seq.cat.2[main$seq.length > 301 & main$seq.length <= 499] <- "301-499"#works
main$seq.cat.2[main$seq.length > 1 & main$seq.length <= 300] <- "100-300"#works
main$seq.cat.2[main$seq.length ==0] <- "Zero"#works

# THE BELOW CREATES A VECTOR OF YEAR CATEGORIES
main["years"] <- gsub("^.*-.*-", "\\1", main$Collection.Date) # Works
main$year.cat[main$years == 2014] <- "2014"#works
main$year.cat[main$years == 2013] <- "2013"#works
main$year.cat[main$years == 2012] <- "2012"#works                                          
main$year.cat[main$years == 2011] <- "2011"#works
main$year.cat[main$years > 2005 & main$years <= 2010] <- "2005-2010"#works
main$year.cat[main$years > 2000 & main$years <= 2005] <- "2000-2005"#works
main$year.cat[main$years > 1990 & main$years <= 2000] <- "1990-2000"#works
main$year.cat[main$years > 1980 & main$years <= 1990] <- "1980-1990"#works
main$year.cat[main$years > 1970 & main$years <= 1980] <- "1970-1980"#works
main$year.cat[main$years > 1960 & main$years <= 1970] <- "1960-1970"#works
main$year.cat[main$years > 1950 & main$years <= 1960] <- "1950-1960"#works
main$year.cat[main$years > 1940 & main$years <= 1950] <- "1940-1950"#works
main$year.cat[main$years > 1930 & main$years <= 1940] <- "1930-1940"#works
main$year.cat[main$years > 1920 & main$years <= 1930] <- "1920-1930"#works
main$year.cat[main$years > 1910 & main$years <= 1920] <- "1910-1920"#works
main$year.cat[main$years > 1900 & main$years <= 1910] <- "1900-1910"#works
main$year.cat[main$years > 1890 & main$years <= 1900] <- "1890-1900"#works

# THE BELOW CREATES A MORE CONCISE VECTOR OF YEAR CATEGORIES
main["alternate.years"] <- gsub("^.*-.*-", "\\1", main$Collection.Date) # Works
#main$concise.year.cat[main$alternate.years == 2014] <- "2014"#works
#main$concise.year.cat[main$alternate.years == 2013] <- "2013"#works
main$concise.year.cat[main$alternate.years == 2012] <- "2012"#works                                          
main$concise.year.cat[main$alternate.years == 2011] <- "2011"#works
main$concise.year.cat[main$alternate.years > 2005 & main$alternate.years <= 2010] <- "2005-2010"#works
main$concise.year.cat[main$alternate.years > 2000 & main$alternate.years <= 2005] <- "2000-2005"#works
main$concise.year.cat[main$alternate.years > 1990 & main$alternate.years <= 2000] <- "1990-2000"#works
main$concise.year.cat[main$alternate.years > 1980 & main$alternate.years <= 1990] <- "1980-1990"#works
main$concise.year.cat[main$alternate.years > 1970 & main$alternate.years <= 1980] <- "1970-1980"#works
main$concise.year.cat[main$alternate.years > 1960 & main$alternate.years <= 1970] <- "1960-1970"#works
main$concise.year.cat[main$alternate.years > 1950 & main$alternate.years <= 1960] <- "1950-1960"#works
main$concise.year.cat[main$alternate.years > 1900 & main$alternate.years <= 1950] <- "1900-1950"#works

# THE BELOW CREATES A VECTOR OF CATEGORIES BASED ON IDENTIFICATION BY: taxonomist, museum, other, or not ID'd
# Below, the groups: recognized, and unrecognized taxonomists are arbitrary groups, created by me, to denote taxonomists that are relatively more known, whose work is readily accepted.
# Museum ID are de-facto identifications by a collection's inclusion of an otherwise unID'd specimen, in a unit tray for a species
# Autoid are specimens ID'd through a BOLD Identification system.
autoid <- c("BOLD ID Run", "BOLD ID Engine")
museumid <- c("Smithsonian Institution Curators", "C. N. C. Curators", "University Of Delaware Curators")
recognized <- c("A. Equihua-martinez", "A. Jansson", "Alex Smith", "Andrew M. R. Bennett", "Andy Hamilton", "Andy Jensen", "Anne H. Mckee", "C. L. Smith", "C. R. Bartlett", "C. V. Reichart", "Charles Bartlett", "Cho Kai Chan", "D. A. Rider", "D. B. Thomas", "D. D. Kopp", "D. E. Leonard", "D. Larson", "D. Punzalan", "David Rider", "David Zamparo", "Eric Harvey", "Eric Maw", "Ernst Heiss", "G. G. E. Scudder", "G. M. Stonedahl", "Gergin A. Blagoev", "H. B. Hangerford", "H. G. Barber", "H. H. Knight", "H. M. Parehley", "H. U. Brailovsky", "Hilary M. Lyttle", "I. M. Kerzhner", "J. F. Roch", "J. T. Polhemus", "James N. Zahniser", "Jeff H. T. Strohm", "Jeffrey H. Skevington", "Keith S. Pike", "L. A. Kelton", "Leland M. Humble", "M. C. Lariviere", "M. D. Schwartz", "M. J. Rothschild", "Michael D. Schwartz", "Nathan Havill", "P. P. Tinerella", "R. C. Froeschner", "R. J. Gill", "R. T. Schuh", "Rob Roughley", "Robert Foottit", "Rodger A. Gwiazdowski", "S. M. Paiero", "Syd Cannings", "T. J. Henry")
unrecognized <- c("A. Asquith", "A. L. Estevez", "A. M. Egbert", "Andrew J. Frewin", "B. A. Harrison", "B. V. Peterson", "Caitlin Vandermeer", "D. Bennett", "D. Forero", "D. V. Bennett", "D. Wyniger", "Dolling Yonke", "F. N. Young", "F. W. Mead", "G. Cassis", "G. Graf", "G. S. Walley", "Hamida B. Mirwan", "I. Lansbury", "Ira La Rivers", "J. C. Lutz", "J. D. Lattin", "J. E. Eger", "J. L. Herring", "Jane M. Caldwell", "Jeremy deWaard", "Jessica L. Lankshear", "Jonathan Witt", "Kate A. Pare", "L. Berniker", "L. R. Penner", "Lena L. van Seggelen", "N. Moller Andersen", "N. P. Chopra", "P. H. Manly", "P. J. Kramer", "P. Kittle", "P. W. Oman", "Pablo M. Dellape", "Paul Hebert", "R. D. Kenner", "R. E. Rodock", "R. H. Beamer", "R. I. S.", "R. I. Sailer", "R. J. Lamb", "Renee Labbee", "Robin Smith", "S. Boyd", "Sarah Z. Dungan", "Soo-Jung Suh", "Susan E. Halbert", "T. Dobbs", "T. M. Lewis", "T. R. Yonke", "Tomislav Terzin", "V. D. Picchi", "Victoria Macphail", "W. L. Mcatee", "W. P. Dubose", "Walley")

main$ID.group <- main$Identifier
main$ID.group <- gsub(paste(autoid, collapse = "|"), "Auto ID", main$ID.group)
main$ID.group <- gsub(paste(museumid, collapse = "|"), "Museum ID", main$ID.group)
main$ID.group <- gsub(paste(recognized, collapse = "|"), "Recognized Taxonomist", main$ID.group)
main$ID.group <- gsub(paste(unrecognized, collapse = "|"), "Unrecognized Taxonomist", main$ID.group)
main$ID.group[ is.na(main$ID.group) ] <- "No ID"
unique(main$ID.group)

####### SUBSET A GROUP FOR A DISCORDANCE REPORT 
# Run a BIN Discordance report on all IDd500. Generate a csv of BIN & Rank of Conflict
IDd <- droplevels(subset(main, !is.na(main$cleanspecies))) # These are all specimens ID'd to species
################################################################################################
###### THE DATAFRAME BELOW: IDd500, is THE DNA BARCODE REFERENCE LIBRARY ######
################################################################################################
IDd500 <- droplevels(subset(IDd, IDd$seq.length >=500)) # These are all specimens ID'd to species, with >=500bp
write.csv(IDd500$Process.ID, file = paste("USE_this_file_for_a_Discordance_report_***these_are_ProcessIDs_of_IDd_specimens_with_>500bp_", as.Date(Sys.time()), ".csv", sep = ""), row.names = FALSE)# Use the process ID's to run a discordance report

#### Generate a csv of BIN & rank of conflict, as below. THIS WAS DONE BY HAND, IN EXCEL. THIS IS THE FILE "R_code_suporting_file_concordance_status.csv" THAT SHOULD NOW BE RE-READ BACK INTO THE MAIN DATASET ABOVE.
#Rank.of.Conflict          BIN
#       Concordant BOLD:AAA1279
#       Concordant BOLD:AAA2079
#       Concordant BOLD:AAA2513
#       Concordant BOLD:AAA2670
#       Concordant BOLD:AAA4390
#       Concordant BOLD:AAA5803
################################################################################################
# At this point you will need to add a file like R_code_suporting_file_concordance_status.csv to the working directory, and re-run all code up until this point, before proceeding.
################################################################################################

###### The below generates a list of all identifiers among the reference library specimens.
identifiers <- droplevels(subset(IDd500, !is.na(IDd500$Identifier))) # These are only specimens with an entry in the Identifier Field
Not_IDd <- droplevels(subset(main, is.na(main$cleanspecies) & main$seq.length <=500))
unique.identifiers <- data.frame(table(identifiers$Identifier))
unique.identifiers <- unique.identifiers[with(unique.identifiers, order(-Freq)) , ]
colnames(unique.identifiers)[1] <- "Identifier"
colnames(unique.identifiers)[2] <- "num.of.specimens"
write.csv(unique.identifiers, file = paste("IDENTIFIERS_of_IDd_specimens_with_>500bp_", as.Date(Sys.time()), ".csv", sep = ""), row.names = FALSE)

head(species.table)
###### SUBSET BY CONCORDANT BINS TO GET PROCESS ID'S FOR A SPECIES-LEVEL DISTANCE ANALYSIS
concord.BINs <- droplevels(subset(IDd500, IDd500$concordance.status == "Concordant")) # The concordance.status vector should have been made after re-running the code (as above), after the addition of the "R_code_suporting_file_concordance_status.csv" file.
concord.sp <- concord.BINs[, c("Family", "Genus", "cleanspecies", "Sample.ID", "Suborder", "Process.ID")]
#unique(is.na(concord.sp$Suborder))
write.csv(concord.sp, file = paste("USE_this_file_for_a_Distance_Summary_***these_are_ProcessIDs_of_species_in_Concordant_BINs_", as.Date(Sys.time()), ".csv", sep = ""), row.names = FALSE)
#### Use the Process IDs in the above file to generate a csv of the distance summary on BOLD, as below. BOLD distance summaries are returned as excel spreadsheets.
# Queries with many (hundreds) of specimens per species may exceed the computational ability of BOLD, and queries may need to be done in batches where each batch contains all the members of a given species (so intraspecific distances can be calculated).
#The spreadsheets from BOLD can be quite large, and when recombining them into one file may exceed the row storage limit of excel. Therefore, I converted each batch-as-spreadsheet into a CSV file, and combined them in R, to produce a file formatted as below.
#     species_sp_1         process_ID_1        species_sp_2         process_ID_2             species        distance
#     Catamergus kickapoo   RDBA154-05         Catamergus kickapoo   RFQC116-09       Catamergus kickapoo   0.0000000
#     Catamergus kickapoo   RDBA373-05         Catamergus kickapoo   RFQC116-09       Catamergus kickapoo   0.4944432
#     Catamergus kickapoo   RDBA373-05         Catamergus kickapoo   RDBA154-05       Catamergus kickapoo   0.4944432
#     Aphis neilliae        RDBAB081-06        Aphis neilliae        RFQC031-09       Aphis neilliae        0.0000000
#     Aphis neilliae        RDBAB080-06        Aphis neilliae        RFQC031-09       Aphis neilliae        0.0000000
#     Aphis neilliae        RDBAB080-06        Aphis neilliae        RDBAB081-06      Aphis neilliae        0.0000000

################################################################################################
# Once the distance analyses, and input file are complete, you will need to place the file in the working directory, and read it back in.
################################################################################################

###### CREATE A DISTANCE SUMMARY TABLE FROM EXTERNAL DISTANCE REPORT - this is only done for species in concordant BINs, by using named specimens from concordant BINs (as above).
# The results of the process below, will be added to a species-level summary table based on the Maw et al. 2000 checklist.
distance <- read.csv(file="R_code_suporting_file_r_made_divergence_april_30.csv", header=T, strip.white=TRUE, na.strings=c(""))
mean <- tapply(distance$distance, distance$species, mean)
mean <-round(mean, digits=2)
stder <- function(x) sd(x)/sqrt(length(x)) # this works
SE <- tapply(distance$distance, distance$species, stder)
SE <-round(SE, digits=2)
max <- tapply(distance$distance, distance$species, max)
max <-round(max, digits=2)
min <- tapply(distance$distance, distance$species, min)
min <-round(min, digits=2)
species.distance.summary <- cbind(mean, SE, max, min)
sp.dist.sum <-data.frame((rownames(species.distance.summary)),species.distance.summary)
colnames(sp.dist.sum)[1]="species"
head(sp.dist.sum)

###### THIS CREATES TABLES USED TO CREATE THE 3D CONCORDANCE FIGURE(below), and adds a species number column for each BIN to the IDd500 dataframe
# Note that the 3D Figure can only be automatically viewed if the program XQuartz for MacOSX has been installed: http://xquartz.macosforge.org/landing/ - I apologize for my ignorance of this feature in Windows environments
# The discordance measured here is based on internal discordance per BIN for THIS dataset 'recognized taxonomists' (as measured by number of species per BIN), and not discordance in BOLD).
# The discordance on BOLD is brought in at the level of color per bin. This is an important, but subtle nuance that adds an extra dimension of information, highlighting the difference between information for a species/BIN within a designated Library, and the information at the same species/BIN level on BOLD. 
recognized.taxonomists <- droplevels(subset(identifiers, identifiers$Identifier %in% recognized)) # The list 'recognized' of "recognized" taxonomists was arbitrarliy designated [by Rodger], above.
identifier.list <- data.frame(table(recognized.taxonomists$Identifier))
identifier.list
identifier.list.for.supp.table <- identifier.list[with(identifier.list, order(-Freq)) , ]
colnames(identifier.list.for.supp.table)[1] <- "Identifier"
colnames(identifier.list.for.supp.table)[2] <- "num.of.specimens"
write.csv(identifier.list.for.supp.table, file = paste("IDENTIFIERS_of_IDd_specimens_for_supplementary_discordance_figure_", as.Date(Sys.time()), ".csv", sep = ""), row.names = FALSE)
count <- function(x) {sum(length(x))}
three.D.specimen_number <- tapply(recognized.taxonomists$Process.ID, recognized.taxonomists$BIN, count) # This counts the number of specimens in each BIN
three.D.species_number <- tapply(recognized.taxonomists$Species, recognized.taxonomists$BIN, function(x) length(na.omit(unique(x)))) # This counts the number of species in each BIN
rec.id <- cbind(three.D.specimen_number, three.D.species_number)
rec.id<-data.frame(as.character(rownames(rec.id)),rec.id)
names(rec.id)[names(rec.id)=="as.character.rownames.rec.id.."] <- "BIN"
rec.id$family <- recognized.taxonomists$Family[match(rec.id$BIN, recognized.taxonomists$BIN)]
rec.id$concordance.status <- recognized.taxonomists$concordance.status[match(rec.id$BIN, recognized.taxonomists$BIN)] # This vector, used to create color, brings in results from the prior BOLD discordance analysis to show BIN discordance as recognized by BOLD.
rec.id$concordance.color <- rec.id$concordance.status
rec.id$concordance.color <- gsub("Concordant", "#339999", rec.id$concordance.color)
rec.id$concordance.color <- gsub("Singleton", "#6699cc", rec.id$concordance.color)
rec.id$concordance.color <- gsub("Order", "#ff0000", rec.id$concordance.color)
rec.id$concordance.color <- gsub("Genus", "#cccc33", rec.id$concordance.color)
rec.id$concordance.color <- gsub("Species", "#cc9900", rec.id$concordance.color)
install.packages("rgl")
require(rgl)
rec.id$concordance.color <- as.character(rec.id$concordance.color) # This appears to be key (for reasons I don't yet understand), if not set as character, the colors are kept as default.
big.three.families <- droplevels(subset(rec.id, rec.id$family %in% c("Miridae", "Aphididae", "Cicadellidae")))
length(unique(big.three.families$BIN)) # This is the number of BINs per family (used in the discordance figure)
big.three.taxonomists <-droplevels(subset(recognized.taxonomists, recognized.taxonomists$BIN %in% big.three.families$BIN))
big.three.identifiers <-data.frame(table(big.three.taxonomists$Identifier))
big.three.identifier.list.for.supp.table <- big.three.identifiers[with(big.three.identifiers, order(-Freq)) , ]
colnames(big.three.identifier.list.for.supp.table)[1] <- "Identifier"
colnames(big.three.identifier.list.for.supp.table)[2] <- "num.of.specimens"
write.csv(big.three.identifier.list.for.supp.table, file = paste("IDENTIFIERS_of_IDd_specimens_for_discordance_figure_", as.Date(Sys.time()), ".csv", sep = ""), row.names = FALSE)
Big.three.BIN_number <- tapply(big.three.families$BIN, big.three.families$family, count) # This calculates the number of BINs per family 
Big.three.BIN_number #
big.three.families$concordance.color <- as.character(big.three.families$concordance.color) # This appears to be key (for reasons I don't yet understand), if not set as character, the colors are kept as default.
require(rgl)
# The four lines below, create the 3D plot, and are continuous - they should be selected and run alltogether.
plot3d(big.three.families$three.D.specimen_number, big.three.families$three.D.species_number, big.three.families$family, col=big.three.families$concordance.color, size=2.3, type='s', xlab = "Specimens in BIN", ylab = "Species in BIN", zlab =".")
aspect3d(1,1,0.5)
axes3d(zat=seq_along(levels(big.three.families$family)), zlab=levels(big.three.families$family), box=TRUE)
grid3d(c("x", "y", "z"), col = "gray")
#ppbig.three.families <- par3d(no.readonly=TRUE) # Set a plot to the orientation you like, then make this
#dput(ppbig.three.families, file="ppbig.three.families.R", control = "all") # This saves the orientation to a file, that can be read in, in the future.
orientppbig.three.families <- structure(list(FOV = 30, ignoreExtent = FALSE, mouseMode = structure(c("trackball", 
                                             "zoom", "fov"), .Names = c("left", "right", "middle")), skipRedraw = FALSE, 
                                             userMatrix = structure(c(-0.307885646820068, -0.259420692920685, 
                                              0.915372431278229, 0, 0.951089262962341, -0.0584180168807507, 
                                              0.303343087434769, 0, -0.0252191238105297, 0.963996171951294, 
                                              0.264718323945999, 0, 0, 0, 0, 1), .Dim = c(4L, 4L)), scale = c(0.583112180233002, 
                                              4.15038681030273, 16.2873554229736), zoom = 0.61594820022583, 
                                             windowRect = c(1448L, 72L, 2809L, 832L), family = "sans", 
                                             font = 1L, cex = 1, useFreeType = TRUE), .Names = c("FOV", 
                                             "ignoreExtent", "mouseMode", "skipRedraw", "userMatrix", "scale", 
                                              "zoom", "windowRect", "family", "font", "cex", "useFreeType"))
  
# This reads in a prior plot orientation
par3d(orientppbig.three.families) # This orients the plot, based on the saved orientation. #http://stackoverflow.com/questions/16362381/save-the-orientation-of-a-rgl-plot3d-plot
#rgl.postscript("June_03th.pdf","pdf") # This saves an image of the plot, as a PDF
######

#The Below plots the Supplementary 3D plot, using all Families
plot3d(rec.id$three.D.specimen_number, rec.id$three.D.species_number, rec.id$family, col=rec.id$concordance.color, size=2.3, type='s', xlab = "Specimens in BIN", ylab = "Species in BIN", zlab = ".")
aspect3d(1,1,3.5)
axes3d(zat=seq_along(levels(rec.id$family)), zlab=levels(rec.id$family), box=TRUE)
grid3d(c("x", "y", "z"), col = "gray")
orientation <- structure(list(FOV = 30, ignoreExtent = FALSE, mouseMode = structure(c("trackball", 
                        "zoom", "fov"), .Names = c("left", "right", "middle")), skipRedraw = FALSE, 
                         userMatrix = structure(c(-0.604950487613678, -0.0764312818646431, 
                         0.792585730552673, 0, 0.796176552772522, -0.0433991141617298, 
                         0.603506147861481, 0, -0.0117291444912553, 0.996130168437958, 
                         0.0871071517467499, 0, 0, 0, 0, 1), .Dim = c(4L, 4L)), scale = c(0.632087826728821, 
                          4.49897813796997, 5.23096227645874), zoom = 0.866700649261475, 
                          windowRect = c(1495L, 79L, 2429L, 1136L), family = "sans", 
                          font = 1L, cex = 1, useFreeType = TRUE), .Names = c("FOV", 
                          "ignoreExtent", "mouseMode", "skipRedraw", "userMatrix", "scale", 
                           "zoom", "windowRect", "family", "font", "cex", "useFreeType"))
par3d(orientation)
#pp <- par3d(no.readonly=TRUE) # Set a plot to the orientation you like, then make this

#### The below writes the files for projects and subsequent DOIs, on BOLD.
write.csv(main$Process.ID, file = paste("Main_process_IDs_", as.Date(Sys.time()), ".csv", sep = ""), row.names = FALSE) 
write.csv(new.releases$Process.ID, file = paste("new_releases_process_IDs_", as.Date(Sys.time()), ".csv", sep = ""), row.names = FALSE) 
write.csv(IDd500$Process.ID, file = paste("IDd500_process_IDs_", as.Date(Sys.time()), ".csv", sep = ""), row.names = FALSE) 
write.csv(recognized.taxonomists$Process.ID, file = paste("Taxonomist_3D_process_IDs_", as.Date(Sys.time()), ".csv", sep = ""), row.names = FALSE) 
#already.published <- c("HCNC", "RFADL", "RDBA", "DBSI", "DIMC") # These are the projects in the main df that have already been released
#new.releases <- droplevels (subset(main, !(main$Project.Code %in% already.published ))) # 

########################################################################################################
#                                            TABLES
########################################################################################################

############# SPECIES-LEVEL TABLE ADAPTED ON THE MAW ET AL. CHECKLIST ##################################
# The below will add species level attributes to the prevoiusly read in version of othe Maw et al. 2000 checklist creating a dataframe called 'species.table'.
# This "species.table" summarizes, respectively, species level attributes for every checklist species matching the "Main" and "Library" datasets.
species.table <- checklist # The checklist (a CSV version of the Maw et al. 2000 checklist) was read in at the very beginning of the code.
accepted.name <- droplevels(subset(check.on.col, check.on.col$status == "accepted name"))
other.name <- droplevels(subset(check.on.col, check.on.col$status != "accepted name"))
unique.other.name <- droplevels(subset(other.name, !(other.name$name %in% accepted.name$name)))
species.table$accepted <- accepted.name$status[match(species.table$checklist_species, accepted.name$name)]
species.table$other <- unique.other.name$status[match(species.table$checklist_species, unique.other.name$name)]
species.table$COL.Status <- paste(species.table$accepted,species.table$other, sep="")
species.table$COL.Status <- gsub("NA", "", species.table$COL.Status)
species.table$COL.Status[species.table$COL.Status == ""] <- "Not on COL"
species.table$accepted <- NULL
species.table$other <- NULL
# This counts all the specimens, named to species, for all the data that can be released.
count_of_all_species <- data.frame(table(main$cleanspecies))
colnames(count_of_all_species)[colnames(count_of_all_species) == "Var1"] <- "totalspecies"
species.table$Public.on.BOLD <- count_of_all_species$Freq[match(species.table$checklist_species, count_of_all_species$totalspecies)]
#This counts all the specimens in the Library dataset
count_of_IDd500 <- data.frame(table(IDd500$cleanspecies))
colnames(count_of_IDd500)[colnames(count_of_IDd500) == "Var1"] <- "totalspecies"
species.table$total.library.specimens.on.BOLD <- NULL
species.table$total.in.library <- count_of_IDd500$Freq[match(species.table$checklist_species, count_of_IDd500$totalspecies)]
# This lists the intraspecific divergence (sp.dist.sum df), calculated above
dist.specimens.per.species <- data.frame(table(specimens.for.distance$cleanspecies)) # These are the # of specimens/species used to create the distance report, and their totals are calculated here. Drawing a specimen.per.species count directly from the distance report is confounded by the multiple pairwise comparisons which artifically elevate the specimen occurances per species in the results file. Also, singletons are not analyzed during a distance analysis, and are not returned with the results.
colnames(dist.specimens.per.species)[1] <- "species"
colnames(dist.specimens.per.species)[2] <- "number.of.specimens"
head(dist.specimens.per.species)
species.table$specimens.in.dist.analysis <- dist.specimens.per.species$number.of.specimens[match(species.table$checklist_species, dist.specimens.per.species$species)]
species.table$mean <- sp.dist.sum$mean[match(species.table$checklist_species, sp.dist.sum$species)]
species.table$SE <- sp.dist.sum$SE[match(species.table$checklist_species, sp.dist.sum$species)]
species.table$max <- sp.dist.sum$max[match(species.table$checklist_species, sp.dist.sum$species)]
species.table$min <- sp.dist.sum$min[match(species.table$checklist_species, sp.dist.sum$species)]
head(species.table)

###### This calculates, and plots potential cryptic species
divergent.species <- droplevels(subset(species.table, species.table$mean >= 2))
write.csv(divergent.species, file = paste("Library_species_with_>_2_Pcent_mean_divergence_", as.Date(Sys.time()), ".csv", sep = ""), row.names = FALSE)

###### CREATE A TABLE OF REFERENCE LIBRARY SPECIES SHARING BARCODES, BASED ON THE NUMBER OF SPECIES IN A BIN, AND ATTACH THIS TO THE "SPECIES.TABLE"
# This is essentially a local BIN discordance analysis, using just the specimens from the Library.
specimen_number <- tapply(IDd500$Process.ID, IDd500$BIN, count) # This counts the specimens per bin from the reference library
species_number <- tapply(IDd500$Species, IDd500$BIN, function(x) length(na.omit(unique(x)))) # This counts the species per bin from the reference library
sharing <- cbind(specimen_number, species_number)
sharing<-data.frame(as.character(rownames(sharing)),sharing)
names(sharing)[names(sharing)=="as.character.rownames.sharing.."] <- "BIN"
sharing$family <- IDd500$Family[match(sharing$BIN, IDd500$BIN)]
sharing$library.BIN.has.multiple.species[sharing$species_number == 1] <- "No"#works
sharing$library.BIN.has.multiple.species[sharing$species_number >1 ] <- "Yes"#works
as.data.frame(sharing)
head(sharing)

#species.table$species.share.bar <- species.share$sharing[match(species.table$checklist_species, species.share$species)]
IDd500$number.of.species.in.BIN <- sharing$species_number[match(IDd500$BIN, sharing$BIN)]
species.table$sharing.numbers <- IDd500$number.of.species.in.BIN[match(species.table$checklist_species, IDd500$cleanspecies)]
species.table$Lib.species.share.barcode[species.table$sharing.numbers == 0] <- "NA"
species.table$Lib.species.share.barcode[species.table$sharing.numbers == 1] <- "No"
species.table$Lib.species.share.barcode[species.table$sharing.numbers >1 ] <- "Yes"
species.table$num.Lib.species.sharing.barcodes <- IDd500$number.of.species.in.BIN[match(species.table$checklist_species, IDd500$cleanspecies)]
species.table$sharing.numbers <- NULL
#write.csv(species.table, file="latest_check_For_sp_num_NOW.csv")
#species.table$total.on.BOLD <- count_of_all_species$Freq[match(species.table$checklist_species, count_of_all_species$totalspecies)]
head(species.table)

# This counts the number of Library BINs per species
BINS.per.species <- tapply(IDd500$BIN, IDd500$cleanspecies, function(x) count (na.omit(unique(x))))
the.BINS <-data.frame((rownames(BINS.per.species)),BINS.per.species)
colnames(the.BINS)[1]="species"
species.table$Library.BINs.per.species <- the.BINS$BINS.per.species[match(species.table$checklist_species, the.BINS$species)]
# This lists the number of specimens in each discordance category, as per the BOLD discordance report
concord.table <- table(IDd500$cleanspecies, IDd500$concordance.status)
concord.by.sp <- as.data.frame.matrix(concord.table)
concordance.by.species <-data.frame((rownames(concord.by.sp)),concord.by.sp)
colnames(concordance.by.species)[1]="species"
head(concordance.by.species)
species.table$specimens.in.a.BOLD.Concordant.BIN <- concordance.by.species$Concordant[match(species.table$checklist_species, concordance.by.species$species)]
species.table$specimens.in.a.BOLD.Singleton.BIN <- concordance.by.species$Singleton[match(species.table$checklist_species, concordance.by.species$species)]
species.table$specimens.in.a.BOLD.BIN.discord.to.Species<- concordance.by.species$Species[match(species.table$checklist_species, concordance.by.species$species)]
species.table$specimens.in.a.BOLD.BIN.discord.to.Genus <- concordance.by.species$Genus[match(species.table$checklist_species, concordance.by.species$species)]
species.table$specimens.in.a.BOLD.BIN.discord.to.Order <- concordance.by.species$Order[match(species.table$checklist_species, concordance.by.species$species)]
species.table$specimens.in.a.BIN.Contaminated.on.BOLD <- concordance.by.species$Contaminated[match(species.table$checklist_species, concordance.by.species$species)]
head(species.table)
write.csv(species.table, file = paste("TABLE_Checklist_based_Species_Table_w_species.level_summaries_", as.Date(Sys.time()), ".csv", sep = ""), row.names = FALSE)

# This Calculates the number of Library species that are singleton and concordant within the library, and on BOLD
only.lib <- droplevels(subset(species.table, species.table$Lib.species.share.barcode %in% "No"))
nrow(only.lib)
uniq.only.lib <-only.lib[!duplicated(only.lib$checklist_species),]
nrow(uniq.only.lib) # 1250 species
#write.csv(uniq.only.lib, file="uniq.only.lib.csv")
singletons <- droplevels(subset(uniq.only.lib, uniq.only.lib$total.in.library == 1))
nrow(singletons) #373 This is the total of species represented by singletons in the Library, in single BINs
lib.concord <- droplevels(subset(uniq.only.lib, uniq.only.lib$total.in.library > 1))                         
nrow(lib.concord) #877 This is the total of concordant species, represented by two or more specimens in concordant BINs in the library
bold.concord <-droplevels(subset(uniq.only.lib, uniq.only.lib$specimens.in.a.BOLD.Concordant.BIN >=1))
nrow(bold.concord) # 882
bold.single <- droplevels(subset(uniq.only.lib, uniq.only.lib$specimens.in.a.BOLD.Singleton.BIN >=1))
nrow(bold.single)
bold.singletons <- droplevels(subset(bold.single, !(bold.single$checklist_species %in% bold.concord$checklist_species)))
str(bold.singletons) #
unique(bold.singletons$checklist_species)


#############           ORDINAL LEVEL SUMMARY TABLE            ##################################
#
# The table below summarizes the contents of the main dataset (data-to-be-released), by Suborder. 
# The below makes summary lists of the number of unique taxa, by suborder
Families <- tapply(main$Family, main$Suborder, function(x) length(na.omit(unique(x))))
Genera <- tapply(main$Genus, main$Suborder, function(x) length(na.omit(unique(x))))
Species <- tapply(main$cleanspecies, main$Suborder, function(x) length(na.omit(unique(x))))
Specimens <- tapply(main$Process.ID, main$Suborder, count) # now that suborder has a not assigned category, this should solve the problem of the missing specimens
main.for.bins <- droplevels (subset(main, !(main$BIN %in% unnamed.bins$BIN )))
total.BINs <- tapply(main$BIN, main$Suborder, function(x) length(na.omit(unique(x))))
Named.BINs <- tapply(main.for.bins$BIN, main.for.bins$Suborder, function(x) length(na.omit(unique(x))))
UnNamed.BINs <- tapply(unnamed.bins$BIN, unnamed.bins$Suborder, function(x) length(na.omit(unique(x))))
# Functions to calculate percentages, and sums
pcentFun <- function(x) {
  (sum(as.numeric(x)) / length(x))
}
count <- function(x) {
  sum(length(x))
}
# End of functions.
# The below calculates proportion of identified specimens, in the main dataset (data-to-be-released), by taxon group (species, genera, family)
# This method copies the taxon vector, turns all entries to a 1, all missing values to a 0, then calculates the proportion for that vector.
main$for.prop.species <- main$cleanspecies
main$for.prop.species <- gsub(".*", "1", main$for.prop.species)
main$for.prop.species[is.na(main$for.prop.species)] <- 0
Prop.Named.Specimens <- tapply(main$for.prop.species, main$Suborder, pcentFun)
Prop.Named.Specimens <-round(Prop.Named.Specimens, digits=2)
main$for.prop.genus <- main$Genus
main$for.prop.genus <- gsub(".*", "1", main$for.prop.genus)
main$for.prop.genus[is.na(main$for.prop.genus)] <- 0
Prop.Named.Genera <- tapply(main$for.prop.genus, main$Suborder, pcentFun)
Prop.Named.Genera <-round(Prop.Named.Genera, digits=2)
main$for.prop.family <- main$Family
unique(main$for.prop.family)
main$for.prop.family <- gsub(".*", "1", main$for.prop.family)
unique(main$for.prop.family)
main$for.prop.family[is.na(main$for.prop.family)] <- 0
unique(main$for.prop.family)
Prop.Named.Family <- tapply(main$for.prop.family, main$Suborder, pcentFun)
Prop.Named.Family.by.family <- tapply(main$for.prop.family, main$Family, pcentFun)
Prop.Named.Family.by.family
Prop.Named.Family <-round(Prop.Named.Family, digits=2)
order.table <- cbind(Families, Prop.Named.Family, Genera, Prop.Named.Genera, Species, total.BINs, UnNamed.BINs, Specimens, Prop.Named.Specimens)
order.table <-data.frame(as.character(rownames(order.table)),order.table)
names(order.table)[names(order.table)=="as.character.rownames.order.table.."] <- "Suborder"
order.table <- order.table[order(order.table$Families) , ]
z <- c("Total", colSums(order.table[,2:10])) # This sums the columns. For reasons I don't understand, the title Total will not replace <NA>.
order.table <- rbind(z, order.table)
order.table
# The contents of this table will be combined with the library table below, for an overall Ordinal-Level summary table.

#############           LIBRARY LEVEL SUMMARY TABLE            ##################################

# The library level summary table summarizes the contents of the Library dataset (IDd500), by Suborder. 

# The below makes summary lists of the number of unique taxa, by suborder
IDd500$over.two <- divergent.species$checklist_species[match(IDd500$cleanspecies, divergent.species$checklist_species)]
Lib.over.two <- tapply(IDd500$over.two, IDd500$Suborder, function(x) length(na.omit(unique(x))))
Lib.Families <- tapply(IDd500$Family, IDd500$Suborder, function(x) length(na.omit(unique(x))))
Lib.Genera <- tapply(IDd500$Genus, IDd500$Suborder, function(x) length(na.omit(unique(x))))
Lib.Species <- tapply(IDd500$cleanspecies, IDd500$Suborder, function(x) length(na.omit(unique(x))))
Lib.Specimens <- tapply(IDd500$Process.ID, IDd500$Suborder, count) #

# The below makes a FAMILY LEVEL SUMMARY TABLE FROM the checklist and library, and calculates proportions
Lib.Family.coverage <- tapply(IDd500$cleanspecies, IDd500$Family, function(x) length(na.omit(unique(x))))
Lib.Family.coverage <-data.frame((rownames(Lib.Family.coverage)),Lib.Family.coverage)
colnames(Lib.Family.coverage)[1]="family"
colnames(Lib.Family.coverage)[2]="library.coverage"
#
checklist.Family.coverage <- tapply(checklist$checklist_species, checklist$family, function(x) length(na.omit(unique(x))))
checklist.Family.coverage <-data.frame((rownames(checklist.Family.coverage)),checklist.Family.coverage)
colnames(checklist.Family.coverage)[1]="family"
colnames(checklist.Family.coverage)[2]="checklist.coverage"
checklist.Family.coverage <- checklist.Family.coverage[order(-checklist.Family.coverage$checklist.coverage) , ]
checklist.Family.coverage$lib.coverage <- Lib.Family.coverage$library.coverage[match(checklist.Family.coverage$family, Lib.Family.coverage$family)]
checklist.Family.coverage$suborder <- checklist$suborder[match(checklist.Family.coverage$family, checklist$family)]
checklist.Family.coverage$lib.proportion <- (checklist.Family.coverage$lib.coverage / checklist.Family.coverage$checklist.coverage)*100
checklist.Family.coverage$lib.proportion <-round(checklist.Family.coverage$lib.proportion, digits=0)
write.csv(checklist.Family.coverage, file = paste("TABLE_Family_level_summary_W_proportion_of_lib_coverage_", as.Date(Sys.time()), ".csv", sep = ""), row.names = FALSE)


#The below calculates proportion of identified specimens, in the main dataset (data-to-be-released), by taxon group (species, genera, family)
Lib.BINs <- tapply(IDd500$BIN, IDd500$Suborder, function(x) length(na.omit(unique(x))))
main$for.prop.genus <- main$Genus
main$for.prop.genus <- gsub(".*", "1", main$for.prop.genus)
main$for.prop.genus[is.na(main$for.prop.genus)] <- 0
Prop.Named.Genera <- tapply(main$for.prop.genus, main$Suborder, pcentFun)
Prop.Named.Genera <-round(Prop.Named.Genera, digits=2)
# All specimens in the library are identified to species

# The functions below calculate percent, and sum
pcentFun <- function(x) {
  (sum(as.numeric(x)) / length(x))
}
count <- function(x) {
  sum(length(x))
}
# End of above functions.

library.table <- cbind(Lib.Families, Lib.Genera, Lib.Species, Lib.BINs, Lib.over.two, Lib.Specimens)   
library.table <-data.frame(as.character(rownames(library.table)),library.table)
names(library.table)[names(library.table)=="as.character.rownames.library.table.."] <- "Suborder"
library.table <- library.table[order(library.table$Family) , ]
as.data.frame(library.table)
z <- c("Total", colSums(library.table[,2:8]))
library.table <- rbind(z, library.table)
as.data.frame(library.table) # for reasons I don't understand the table will not sort by Family in ascending, or descending order.
library.table 

summary.table <- cbind(Lib.Families, Families, Prop.Named.Family, Lib.Genera, Genera, Prop.Named.Genera, Lib.Species, Species, Lib.BINs, total.BINs, UnNamed.BINs, Lib.over.two, Lib.Specimens, Specimens, Prop.Named.Specimens)
summary.table <-data.frame(as.character(rownames(summary.table)),summary.table)
names(summary.table)[names(summary.table)=="as.character.rownames.summary.table.."] <- "Suborder"
as.data.frame(summary.table)
z <- c("Total", colSums(summary.table[,2:16]))
summary.table <- rbind(z, summary.table)
summary.table <- summary.table[with(summary.table, order(-Lib.Families)) , ] # for reasons I don't understand the table will not sort by Family in ascending, or descending order.
# The below calculates the number of library species sharing barcodes, by suborder.
IDd500$who.shares <- species.table$Lib.species.share.barcode[match(IDd500$cleanspecies, species.table$checklist_species)]
Lib.who.shares <- droplevels(subset(IDd500, IDd500$who.shares =="Yes"))
Lib.spp.sharing.barcodes <- tapply(Lib.who.shares$cleanspecies, Lib.who.shares$Suborder, function(x) length(na.omit(unique(x))))
Lib.spp.sharing.barcodes <-data.frame((rownames(Lib.spp.sharing.barcodes)),Lib.spp.sharing.barcodes)
colnames(Lib.spp.sharing.barcodes)[1]="Suborder"
head(Lib.spp.sharing.barcodes)#These numbers seem OK, but do not include any not.assigned values. I don't know how to make this automatically fit the table directly, so I'm using an index match, at the end.
summary.table$Lib.spp.sharing.barcodes <- Lib.spp.sharing.barcodes$Lib.spp.sharing.barcodes[match(summary.table$Suborder, Lib.spp.sharing.barcodes$Suborder)]
summary.table
write.csv(summary.table, file = paste("TABLE_Summary_of_Library_and_Main_dataset_contents_", as.Date(Sys.time()), ".csv", sep = ""), row.names = FALSE)
########################################################################################################
#                                                  END TABLES
########################################################################################################


########################################################################################################
#                                                   FIGURES
########################################################################################################

###### CREATE A PROPORTIONAL HISTOGRAM OF GENERAL DATA-SOURCES, FILLED WITH SEQUENCE LENGTH
main$seq.cat <- as.factor(main$seq.cat)
main$source.group <- ordered(main$source.group, levels = c("BioBus", "Malaise", "BIO related", "Museum"))
main$seq.cat <- ordered(main$seq.cat, levels = c("Zero", "0-100", "100-300", "300-500", "500-658", "over 600"))
install.packages("ggplot2")
require(ggplot2)
install.packages("scales")
require(scales)
p1 <- ggplot(main, aes(x = main$source.group, y = (..count..))) # this puts absolute values on the y scale
p1 <- p1 + geom_bar(aes(fill=main$seq.cat, width=.4))
p1 <- p1 + stat_bin(geom = "text", aes(label = paste(round((..count..)/sum(..count..)*100), "%")), vjust = -.5, color = "black", size = 9)
p1 <- p1 + theme_bw()
#
p1 <- p1 + xlab("") + ylab("")
p1 <- p1 + theme(axis.text.x=element_text(size=rel(3)), # This is the base text
                 axis.title.x=element_text(size=rel(1)),
                 axis.text.y=element_text(size=rel(2),color="black"))
p1 <- p1 + theme(legend.text=element_text(size=20))
p1 <- p1 + guides(fill = guide_legend(reverse = TRUE, title.theme = element_text(size=20, colour = "black", angle = 0)))
#p1 <- p1 + scale_fill_manual(values = c("Zero" = "black", "0-100" ="#C6DBEF", "100-300"="#9ECAE1", "300-500"="#6BAED6", "500-658"="#3182BD", "over 600"="#08519C"))
p1 <- p1 + scale_fill_manual(name="Sequence Lengths", values = c("Zero" = "black", "0-100" ="#C6DBEF", "100-300"="#9ECAE1", "300-500"="#6BAED6", "500-658"="#3182BD", "over 600"="#08519C"))

#p1 <- p1 + guides(fill = guide_legend(title.theme = element_text(size=20, colour = "black", angle = 0)))
#p1 <- p1 + theme(legend.justification=c(1,0), legend.position=c(1,0))
figure_1 <- p1 + theme(legend.position=c(0,1),legend.justification=c(0,1),
      legend.direction="vertical",
      legend.box="horizontal",
      legend.box.just = c("top"), 
      legend.background = element_rect(fill=alpha('white', 0.1)))
print(figure_1)
dev.copy2pdf(file="FIGURE_sequence_sources.pdf")
########################################################################################################
###### CREATE A PROPORTIONAL HISTOGRAM OF LIBRARY DATA-SOURCES, FILLED WITH SEQUENCE LENGTH
IDd500$seq.cat <- as.factor(IDd500$seq.cat)
IDd500$source.group <- ordered(IDd500$source.group, levels = c("BioBus", "Malaise", "BIO related", "Museum"))
IDd500$seq.cat <- ordered(IDd500$seq.cat, levels = c("Zero", "0-100", "100-300", "300-500", "500-658", "over 600"))
install.packages("ggplot2")
require(ggplot2)
install.packages("scales")
require(scales)
p1 <- ggplot(IDd500, aes(x = IDd500$source.group, y = (..count..))) # this puts absolute values on the y scale
p1 <- p1 + geom_bar(aes(fill=IDd500$seq.cat, width=.4))
p1 <- p1 + stat_bin(geom = "text", aes(label = paste(round((..count..)/sum(..count..)*100), "%")), vjust = -.5, color = "black", size = 9)
p1 <- p1 + theme_bw()
p1 <- p1 + xlab("") + ylab("")
p1 <- p1 + theme(axis.text.x=element_text(size=rel(3)), # This is the base text
                 axis.title.x=element_text(size=rel(1)),
                 axis.text.y=element_text(size=rel(2),color="black"))
p1 <- p1 + theme(legend.text=element_text(size=20))
p1 <- p1 + guides(fill = guide_legend(reverse = TRUE, title.theme = element_text(size=20, colour = "black", angle = 0)))
#p1 <- p1 + scale_fill_manual(values = c("Zero" = "black", "0-100" ="#C6DBEF", "100-300"="#9ECAE1", "300-500"="#6BAED6", "500-658"="#3182BD", "over 600"="#08519C"))
p1 <- p1 + scale_fill_manual(name="Sequence Lengths", values = c("Zero" = "black", "0-100" ="#C6DBEF", "100-300"="#9ECAE1", "300-500"="#6BAED6", "500-658"="#3182BD", "over 600"="#08519C"))

#p1 <- p1 + guides(fill = guide_legend(title.theme = element_text(size=20, colour = "black", angle = 0)))
#p1 <- p1 + theme(legend.justification=c(1,0), legend.position=c(1,0))
Supp_figure_2 <- p1 + theme(legend.position=c(0,1),legend.justification=c(0,1),
                 legend.direction="vertical",
                 legend.box="horizontal",
                 legend.box.just = c("top"), 
                 legend.background = element_rect(fill=alpha('white', 0.1)))
print(Supp_figure_2)
dev.copy2pdf(file="FIGURE_Library_sequence_sources.pdf")

########################################################################################################

###### CREATE A HEAT-INDEX BUBBLE DIAGRAM OF PRIMER USAGE AND PROPORTION OF AMPLIFICATION BY FAMILY
# This helps visualize the primers used, their proportions tried, and successful amplifications across the Main-dataset
# The data comes from a special request to the BOLD Team for all primers associated with Process IDs from the Main-dataset
hemip.primers <- read.csv("R_code_suporting_file_RodgPrimers_Apr17.csv", header =T, strip.white=TRUE, na.strings=c("")) # for other characters na.strings=c("",".","NA")#Works
str(hemip.primers)
code <- read.csv("R_code_suporting_file_primer_code.csv", header =T, strip.white=TRUE, na.strings=c("")) # for other characters na.strings=c("",".","NA")#Works
hemip.primers$forward.primer <- code$primer[match(hemip.primers$fk_primer_f, code$code)]
hemip.primers$reverse.primer <- code$primer[match(hemip.primers$fk_primer_r, code$code)]
hemip.primers$seq.primer <- code$primer[match(hemip.primers$fk_primer_seq, code$code)]
hemip.primers$primers <- paste(hemip.primers$forward.primer,hemip.primers$reverse.primer, sep="_") 
hemip.primers$taxonomy <- main$Family[match(hemip.primers$processid, main$Process.ID)]
hemip.primers$success <- hemip.primers$status
hemip.primers$success <- gsub("failed", "0", hemip.primers$success) # The results from the BOLD search qualify the sequence quality. To simplify the calculation of proportions, I've coded anything amplifying as 1, anything not as 0.
hemip.primers$success <- gsub("low qual", "1", hemip.primers$success)
hemip.primers$success <- gsub("med qual", "1", hemip.primers$success)
hemip.primers$success <- gsub("high qual", "1", hemip.primers$success)
full <- data.frame(table(hemip.primers$primers))
full <- full[order(-full$Freq),] #orders df by the primer frequency
full

# The below breaks up the primers into subsets, from which amplification proportions, and sums are calculated.
# THE BELOW CAN ALL BE WRITTEN AS A FUNCTION, TO AUTOMATICALLY ACCOMODATE ANY NUMBER OF PRIMERS, FROM ANY INPUT FILE - but I need to take a few hours to puzzle that out.
primer1 <- droplevels(subset(hemip.primers, hemip.primers$primers=="AncientLepF2_MLepR2"))
primer2 <- droplevels(subset(hemip.primers, hemip.primers$primers=="C_microLepF1_t1_C_TypeR1"))
primer3 <- droplevels(subset(hemip.primers, hemip.primers$primers=="MHemF_C_LepFolR"))
primer4 <- droplevels(subset(hemip.primers, hemip.primers$primers=="C_tRWFt1_MHemR"))
primer5 <- droplevels(subset(hemip.primers, hemip.primers$primers=="LCO1490_HCO2198"))
primer6 <- droplevels(subset(hemip.primers, hemip.primers$primers=="C_LepFolF_MHemR"))
primer7 <- droplevels(subset(hemip.primers, hemip.primers$primers=="MLepF1_LepR1"))
primer8 <- droplevels(subset(hemip.primers, hemip.primers$primers=="PcoF_LepR1"))
#primer9 <- droplevels(subset(hemip.primers, hemip.primers$primers=="HCO2198_t1_LCO1490_t1"))
str(primer9)
primer10 <- droplevels(subset(hemip.primers, hemip.primers$primers=="LepF1_ANTMR1D"))
primer11 <- droplevels(subset(hemip.primers, hemip.primers$primers=="MLepF2_t1_microLepR2_t1"))
primer12 <- droplevels(subset(hemip.primers, hemip.primers$primers=="MLepF1_HCO2198_t1"))
primer13 <- droplevels(subset(hemip.primers, hemip.primers$primers=="MLepF1_C_LepFolR"))
primer14 <- droplevels(subset(hemip.primers, hemip.primers$primers=="C_LepFolF_MLepR2"))
primer15 <- droplevels(subset(hemip.primers, hemip.primers$primers=="LepR1_LepF1"))
primer16 <- droplevels(subset(hemip.primers, hemip.primers$primers=="LCO1490_t1_MLepR1"))
primer17 <- droplevels(subset(hemip.primers, hemip.primers$primers=="LepF1_MLepR1"))
primer18 <- droplevels(subset(hemip.primers, hemip.primers$primers=="MLepF1_LepR1_t1"))
primer19 <- droplevels(subset(hemip.primers, hemip.primers$primers=="RonMWASPdeg_t1_LepR1"))
primer20 <- droplevels(subset(hemip.primers, hemip.primers$primers=="LepF1_C_ANTMR1D"))
primer21 <- droplevels(subset(hemip.primers, hemip.primers$primers=="LepF2_t1_LepR1"))
primer22 <- droplevels(subset(hemip.primers, hemip.primers$primers=="MHemF_LepR1"))
primer23 <- droplevels(subset(hemip.primers, hemip.primers$primers=="C_LepFolF_C_LepFolR"))
primer24 <- droplevels(subset(hemip.primers, hemip.primers$primers=="LepF2_t1_MHemR"))
primer25 <- droplevels(subset(hemip.primers, hemip.primers$primers=="LepF1_LepR1"))
primer26 <- droplevels(subset(hemip.primers, hemip.primers$primers=="LCO1490_t1_HCO2198_t1"))
primer27 <- droplevels(subset(hemip.primers, hemip.primers$primers=="C_tRWFt1_LepR1"))

# The functions below calculate percent, and sum
pcentFun <- function(x) {
  (sum(as.numeric(x)) / length(x))
}
count <- function(x) {
  sum(length(x))
}
# End of above functions.
success <- tapply(primer1$success, primer1$taxonomy, pcentFun)
totalspecimens <- tapply(primer1$success, primer1$taxonomy, count)
part1 <- data.frame(success, totalspecimens)
part1$taxonomy <- rownames(part1) 
part1$primer <- "AncientLepF2 & MLepR2"
success <- tapply(primer2$success, primer2$taxonomy, pcentFun)
totalspecimens <- tapply(primer2$success, primer2$taxonomy, count)
part2 <- data.frame(success, totalspecimens)
part2$taxonomy <- rownames(part2) 
part2$primer <- "C_microLepF1_t1 & C_TypeR1"
part2
success <- tapply(primer3$success, primer3$taxonomy, pcentFun)
totalspecimens <- tapply(primer3$success, primer3$taxonomy, count)
part3 <- data.frame(success, totalspecimens)
part3$taxonomy <- rownames(part3) 
part3$primer <- "MHemF & C_LepFolR"
part3
success <- tapply(primer4$success, primer4$taxonomy, pcentFun)
totalspecimens <- tapply(primer4$success, primer4$taxonomy, count)
part4 <- data.frame(success, totalspecimens)
part4$taxonomy <- rownames(part4) 
part4$primer <- "C_tRWFt1 & MHemR"
part4
success <- tapply(primer5$success, primer5$taxonomy, pcentFun)
totalspecimens <- tapply(primer5$success, primer5$taxonomy, count)
part5 <- data.frame(success, totalspecimens)
part5$taxonomy <- rownames(part5) 
part5$primer <- "LCO1490 & HCO2198"
part5
success <- tapply(primer6$success, primer6$taxonomy, pcentFun)
totalspecimens <- tapply(primer6$success, primer6$taxonomy, count)
part6 <- data.frame(success, totalspecimens)
part6$taxonomy <- rownames(part6) 
part6$primer <- "C_LepFolF & MHemR"
part6
success <- tapply(primer7$success, primer7$taxonomy, pcentFun)
totalspecimens <- tapply(primer7$success, primer7$taxonomy, count)
part7 <- data.frame(success, totalspecimens)
part7$taxonomy <- rownames(part7) 
part7$primer <- "MLepF1 & LepR1"
part7
success <- tapply(primer8$success, primer8$taxonomy, pcentFun)
totalspecimens <- tapply(primer8$success, primer8$taxonomy, count)
part8 <- data.frame(success, totalspecimens)
part8$taxonomy <- rownames(part8) 
part8$primer <- "PcoF & LepR1"
part8
#str(primer9) # This category is based on an error in primer naming from the BOLD team, the error has been fixed, and this section is no longer necessary.
#write.csv(primer9, file="primer9.csv")
#success <- tapply(primer9$success, primer9$taxonomy, pcentFun)
#totalspecimens <- tapply(primer9$success, primer9$taxonomy, count)
#part9 <- data.frame(success, totalspecimens)
#part9$taxonomy <- rownames(part9) 
#part9$primer <- "HCO2198_t1 & LCO1490_t1"
#part9
success <- tapply(primer10$success, primer10$taxonomy, pcentFun)
totalspecimens <- tapply(primer10$success, primer10$taxonomy, count)
part10 <- data.frame(success, totalspecimens)
part10$taxonomy <- rownames(part10) 
part10$primer <- "LepF1 & ANTMR1D"
part10
success <- tapply(primer11$success, primer11$taxonomy, pcentFun)
totalspecimens <- tapply(primer11$success, primer11$taxonomy, count)
part11 <- data.frame(success, totalspecimens)
part11$taxonomy <- rownames(part11) 
part11$primer <- "MLepF2_t1 & microLepR2_t1"
part11
success <- tapply(primer12$success, primer12$taxonomy, pcentFun)
totalspecimens <- tapply(primer12$success, primer12$taxonomy, count)
part12 <- data.frame(success, totalspecimens)
part12$taxonomy <- rownames(part12) 
part12$primer <- "MLepF1 & HCO2198_t1"
part12
success <- tapply(primer13$success, primer13$taxonomy, pcentFun)
totalspecimens <- tapply(primer13$success, primer13$taxonomy, count)
part13 <- data.frame(success, totalspecimens)
part13$taxonomy <- rownames(part13) 
part13$primer <- "MLepF1 & C_LepFolR"
part13
success <- tapply(primer14$success, primer14$taxonomy, pcentFun)
totalspecimens <- tapply(primer14$success, primer14$taxonomy, count)
part14 <- data.frame(success, totalspecimens)
part14$taxonomy <- rownames(part14) 
part14$primer <- "C_LepFolF & MLepR2"
part14
success <- tapply(primer15$success, primer15$taxonomy, pcentFun)
totalspecimens <- tapply(primer15$success, primer15$taxonomy, count)
part15 <- data.frame(success, totalspecimens)
part15$taxonomy <- rownames(part15) 
part15$primer <- "LepR1 & LepF1"
part15
success <- tapply(primer16$success, primer16$taxonomy, pcentFun)
totalspecimens <- tapply(primer16$success, primer16$taxonomy, count)
part16 <- data.frame(success, totalspecimens)
part16$taxonomy <- rownames(part16) 
part16$primer <- "LCO1490_t1 & MLepR1"
part16
success <- tapply(primer17$success, primer17$taxonomy, pcentFun)
totalspecimens <- tapply(primer17$success, primer17$taxonomy, count)
part17 <- data.frame(success, totalspecimens)
part17$taxonomy <- rownames(part17) 
part17$primer <- "LepF1 & MLepR1"
part17
success <- tapply(primer18$success, primer18$taxonomy, pcentFun)
totalspecimens <- tapply(primer18$success, primer18$taxonomy, count)
part18 <- data.frame(success, totalspecimens)
part18$taxonomy <- rownames(part18) 
part18$primer <- "MLepF1 & LepR1_t1"
part18
success <- tapply(primer19$success, primer19$taxonomy, pcentFun)
totalspecimens <- tapply(primer19$success, primer19$taxonomy, count)
part19 <- data.frame(success, totalspecimens)
part19$taxonomy <- rownames(part19) 
part19$primer <- "RonMWASPdeg_t1 & LepR1"
part19
success <- tapply(primer20$success, primer20$taxonomy, pcentFun)
totalspecimens <- tapply(primer20$success, primer20$taxonomy, count)
part20 <- data.frame(success, totalspecimens)
part20$taxonomy <- rownames(part20) 
part20$primer <- "LepF1 & C_ANTMR1D"
part20
success <- tapply(primer21$success, primer21$taxonomy, pcentFun)
totalspecimens <- tapply(primer21$success, primer21$taxonomy, count)
part21 <- data.frame(success, totalspecimens)
part21$taxonomy <- rownames(part21) 
part21$primer <- "LepF2_t1 & LepR1"
part21
success <- tapply(primer22$success, primer22$taxonomy, pcentFun)
totalspecimens <- tapply(primer22$success, primer22$taxonomy, count)
part22 <- data.frame(success, totalspecimens)
part22$taxonomy <- rownames(part22) 
part22$primer <- "MHemF & LepR1"
part22
success <- tapply(primer23$success, primer23$taxonomy, pcentFun)
totalspecimens <- tapply(primer23$success, primer23$taxonomy, count)
part23 <- data.frame(success, totalspecimens)
part23$taxonomy <- rownames(part23) 
part23$primer <- "C_LepFolF & C_LepFolR"
part23
success <- tapply(primer24$success, primer24$taxonomy, pcentFun)
totalspecimens <- tapply(primer24$success, primer24$taxonomy, count)
part24 <- data.frame(success, totalspecimens)
part24$taxonomy <- rownames(part24) 
part24$primer <- "LepF2_t1 & MHemR"
part24
success <- tapply(primer25$success, primer25$taxonomy, pcentFun)
totalspecimens <- tapply(primer25$success, primer25$taxonomy, count)
part25 <- data.frame(success, totalspecimens)
part25$taxonomy <- rownames(part25) 
part25$primer <- "LepF1 & LepR1"
part25
success <- tapply(primer26$success, primer26$taxonomy, pcentFun)
totalspecimens <- tapply(primer26$success, primer26$taxonomy, count)
part26 <- data.frame(success, totalspecimens)
part26$taxonomy <- rownames(part26) 
part26$primer <- "LCO1490_t1 & HCO2198_t1"
part26
success <- tapply(primer27$success, primer27$taxonomy, pcentFun)
totalspecimens <- tapply(primer27$success, primer27$taxonomy, count)
part27 <- data.frame(success, totalspecimens)
part27$taxonomy <- rownames(part27) 
part27$primer <- "C_tRWFt1 & LepR1"
part27

# analyze this, below, pulls together the table summaries for all the primers, above.
analyzethis <- rbind(part1, part2, part3, part4, part5, part6, part7, part8, part10, part11, part12, part13, part14, part15, part16, part17, part18, part19, part20, part21, part22, part23, part24, part25, part26, part27)#
rownames(analyzethis) <- NULL 
data <-analyzethis
data$taxonomy <- as.character(data$taxonomy)
data$taxonomy <- as.character(data$taxonomy, levels = rev(levels(data$taxonomy))) #reverses, the order of a factor
require(ggplot2) 
data$primer <- ordered(data$primer, levels = c("C_microLepF1_t1 & C_TypeR1", "AncientLepF2 & MLepR2", "MLepF2_t1 & microLepR2_t1", "LepF2_t1 & MHemR", "LepF1 & ANTMR1D", "LepF1 & MLepR1", "C_tRWFt1 & MHemR", "C_LepFolF & MLepR2", "C_LepFolF & MHemR", "MLepF1 & LepR1_t1", "MLepF1 & LepR1", "MLepF1 & HCO2198_t1", "MLepF1 & C_LepFolR", "MHemF & LepR1", "MHemF & C_LepFolR", "LCO1490_t1 & MLepR1", "PcoF & LepR1", "LepF2_t1 & LepR1", "LepF1 & LepR1", "HCO2198_t1 & LCO1490_t1", "LCO1490_t1 & HCO2198_t1", "LCO1490 & HCO2198", "C_tRWFt1 & LepR1", "C_LepFolF & C_LepFolR"))
g <- ggplot(data, aes(data$taxonomy, data$primer)) 
g <- g + geom_point(aes(size = data$totalspecimens, color=data$success), alpha = 0.8)
g <- g + labs(color = "Proportion of\namplification")
g <- g + theme_bw() + xlab("") + ylab("") # this plots the graph as horizontal
r <- g + scale_size_area(data$totalspecimens, max_size = 60, guide=FALSE) + geom_text(aes(label = data$totalspecimens, hjust=0.5, vjust=-0.7, size=30)) # works
r <- r + theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1))
r <- r + theme(axis.text.x=element_text(size=rel(2)),
               axis.title.x=element_text(size=rel(1.3)),
               axis.text.y=element_text(size=rel(1.6),color="black"))
Figure_2_primer_plot <- r + theme(legend.position="right",
               legend.direction="vertical",
               legend.box="horizontal",
               legend.box.just = c("top"), 
               legend.background = element_rect(fill=alpha('white', 0.1)))
Figure_2_primer_plot # This is the finished figure

dev.copy2pdf(file="FIGURE_Primer_plot.pdf") # The snapshot view appears to be dependent on the screen view at the time the file is saved. 

########################################################################################################
# CREATE PROPORTIONAL HISTOGRAMS OF SEQUENCE LENGTH BY CONCISE YEAR CATEGORIES FROM THE MAIN  DATASET (data-for-release)
# This histogram uses the age categories, calculated above.
age.other <- droplevels(subset(main,complete.cases(main$years)))
age2 <- droplevels(subset(age.other,!(age.other$years=="2013")))
age2$seq.cat.2 <- ordered(age2$seq.cat.2, levels = c("Zero", "100-300", "301-499", "500-658", "over 600"))
#age2$seq.cat.2 <- ordered(age2$seq.cat.2, levels = c("over 600","500-658","300-500","100-300","0-100","Zero"))
age2$concise.year.cat <- ordered(age2$concise.year.cat, levels = c("1900-1950","1950-1960","1960-1970","1970-1980","1980-1990","1990-2000","2000-2005","2005-2010","2011","2012"))
require(ggplot2)
p1 <- ggplot(age2, aes(x = age2$concise.year.cat, y = (..count..))) # this put absolute values on the y scale
p1 <- p1 + geom_bar(aes(fill=age2$seq.cat.2, width=.4))
#p1 <- p1 + stat_bin(geom = "text", aes(label = paste(round((..count..)/sum(..count..)*100), "%")), vjust = -.5, color = "grey30", size = 7)
p1 <- p1 + stat_bin(geom = "text", aes(label = paste(round((..count..)/sum(..count..)*100), "%")), vjust = -.5, color = "grey30", size = 7)
print(p1) # up to here is exactly what I'd like to do.
p1 <- p1 + xlab("") + ylab("")
#p1 <- p1 + scale_y_continuous(label = percent_format())
p1 <- p1 + scale_fill_discrete(name="Sequence Lengths")
p1 <- p1 + theme(axis.text.x=element_text(size=rel(2)),
                 axis.title.x=element_text(size=rel(1)),
                 axis.text.y=element_text(size=rel(1.5),color="black"))
p1 <- p1 + theme(legend.text=element_text(size=20))
Supp_Figure_1 <- p1 + guides(fill = guide_legend(reverse = TRUE, title.theme = element_text(size=20, colour = "black", angle = 0)))
#p1 <- p1 + guides(fill = guide_legend(title.theme = element_text(size=20, colour = "black", angle = 0)))
print(Supp_Figure_1)
dev.copy2pdf(file="FIGURE_histogram_of_seq_length_by_concise_year.pdf") # The snapshot view appears to be dependent on the screen view at the time the file is saved.
########################################################################################################
 #;
#END;

